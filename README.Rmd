---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
options(xts.warn_dplyr_breaks_lag = FALSE)
```

# InvestigatoR <a href='https://github.com/sstoeckl/InvestigatoR'><img src='man/figures/Investigator.png' align="right" height="139" style="float:right; height:200px;"/></a>

<!-- badges: start -->
  [![Project Status](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)
  <!-- [![CRAN_latest_release_date](https://www.r-pkg.org/badges/last-release/InvestigatoR)](https://cran.r-project.org/package=InvestigatoR) -->
  <!-- [![CRAN status](https://www.r-pkg.org/badges/version/InvestigatoR)](https://CRAN.R-project.org/package=InvestigatoR) -->
  <!-- [![CRAN downloads](http://cranlogs.r-pkg.org/badges/grand-total/InvestigatoR)](https://cran.r-project.org/package=InvestigatoR) -->
  <!-- [![CRAN downloads last month](http://cranlogs.r-pkg.org/badges/InvestigatoR)](https://cran.r-project.org/package=InvestigatoR) -->
  <!-- [![CRAN downloads last week](http://cranlogs.r-pkg.org/badges/last-week/InvestigatoR)](https://cran.r-project.org/package=InvestigatoR) -->
  <!-- [![Lifecycle: stable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html#stable) -->
  [![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
  [![Website - pkgdown](https://img.shields.io/website-up-down-green-red/https/sstoeckl.github.io/InvestigatoR.svg)](https://sstoeckl.github.io/InvestigatoR/)
<!-- badges: end -->

# "InvestigatoR" that's what she said!

The **goal of InvestigatoR** is to provide a comprehensive toolkit for quantitative finance professionals and researchers to conduct advanced backtesting and portfolio analysis using machine learning models. 

It offers:

- a streamlined *workflow* for loading data
- specifying *features*
- configuring *machine learning models*
- and analyzing the *performance of predictions and portfolio strategies*. 

This facilitates the evaluation of investment strategies, helping users to optimize returns and manage risks more effectively in their financial models.

More in detail, the package allows the user to create:

- `returnPrediction`: An S3 object that contains the results of the backtesting strategy for predicting stock returns. One can subsequently try different prediction algorithms and all save them in the same object. The object then contains, (i) information on the algorithm and parameters used, (ii) the predictions, (iii) the real returns as well as (iv) the respective errors. Using `summary()` on this object will produce common error statistics (MSE, RMSE, MAE, ...).
- `backtesting_returns()`: This function is one of the major workhorses of the package. It predicts a label (mostly the returns, but can also be other labels, such as the volatility) for a set of given assets and dates based on available features. The function allows for different machine learning algorithms, some are pre-implemented, such as linear regression, gradient boosting, and random forests, others can easily be added (see `vignette("custom_predictions")`). It contains a large variety of configuration options, such as rolling or expanding windows, window sizes, step sizes, and offsets. The function adds predictions and all necessary information to the `returnPrediction` S3 object. Currently implemented prediction functions:

    - `ols_pred`: predicts returns using simple linear regression
    - `xgb_pred`: predicts returns using gradient boosted trees
    - `rf_pred`: predicts returns using random forests

In the future we plan a major upgrade to the function to be able to handle caret models as well as other machine learning models.
- `portfolioReturns`: Another S3 object that contains the results of the backtesting strategy for a portfolio. The object contains (i) information on the weight creation strategy and function used, including possible constraints and parameters, (ii) the weights created per asset and date, (iii) the actual asset returns and (iv) the (automatically calculated) portfolio returns. Using `summary()` on this object will produce common performance statistics (mean, stanjdard deviation, Share Ratio, VaR, turnover), but can also handle almost all `PerformanceAnalytics` functions and tables. An additional `plot` routine will produce a cumulative return plot of the portfolio, but can also handle various predefined plots from the `PerformanceAnalytics` package.
- `backtesting_portfolio()`: This function is the second major work horse of the package. It uses the predictions contained in a `returnPrediction` object to create portfolio weights implementing various constraints



lculates the returns of a portfolio strategy based on the predictions. The function allows for different portfolio strategies, such as long-short, long-only, short-only, and equal-weighted. The function also allows for different holding periods, such as daily, weekly, monthly, and yearly. The function returns a data frame with the returns of the portfolio strategy.






# Installation

You can install the development version of InvestigatoR from [GitHub](https://github.com/) with:

```{r install_package}
# install.packages("devtools")
devtools::install_github("sstoeckl/InvestigatoR")
```

# Package History






# Package Usage

This is a basic example which shows you how to solve a common problem:

```{r loaad_package}
library(InvestigatoR)
library(tidyverse)
## basic example code
```

First we load the complimentary dataset that comes with the package:

```{r load_data}
data("data_ml")
data_ml |> distinct(date) |> pull(date) |> min()
data_ml |> distinct(date) |> pull(date) |> max()
```

For a description, see.... The original datset was provided by Guillaume Coqueret and Tony Guida with their book [Machine Learning for Factor Investing](https://mlfactor.com).

Next we specify the set of features that should be used for return prediction, specify some options for backtesting, such as whether the return prediction should be done with a rolling window (TRUE), the window size ("5 years"), the step size("3 months", this means, how often do we reestimate the ML model), the offset ("1 year" to avoid any form of data spillage).

```{r specify_features}
return_label <- "R1M_Usd"
features <- c("Div_Yld", "Eps", "Mkt_Cap_12M_Usd", "Mom_11M_Usd", "Ocf", "Pb", "Vol1Y_Usd")
rolling <- FALSE; window_size= "5 years"; step_size = "1 months"; offset = "1 month"; in_sample = TRUE
```

Next we specify the machine learning configuration. We can specify multiple configurations, for example, one for a linear regression model and one for a gradient boosting model. The configuration for the linear regression model is empty, as we use the default configuration. The configuration for the gradient boosting model specifies the number of rounds, the maximum depth of the trees, the learning rate, and the objective function. Other functions still need to be implemented.

```{r specify_ml_config}
 ml_config <- list(ols_pred = list(pred_func="ols_pred", config=list()),
                   xgb_pred = list(pred_func="xgb_pred", 
                                   config1=list(nrounds=10, max_depth=3, eta=0.3, objective="reg:squarederror"),
                                   config2=list(nrounds=10, max_depth=3, eta=0.1, objective="reg:squarederror")))
```

Finally, we call the backtesting function. The function returns a data frame with the backtesting results. The data frame contains the following columns: date, return_label, features, rolling, window_size, step_size, offset, in_sample, ml_config, model, predicted returns, actual realized returns, and errors for all predictions. The model column contains the name of the model that was used for the prediction. The prediction column contains the predicted returns. The actual column contains the actual returns. The error column contains the difference between the predicted and the actual returns.

```{r backtesting_returns}
 rp <- backtesting_returns(data=data_ml, return_prediction_object=NULL,
   return_label, features, rolling=FALSE, window_size, step_size, offset, in_sample, ml_config, append=FALSE, num_cores=NULL)
```

Next we take this predictions and analyse their statistical properties

```{r analyse_predictions}
rp$predictions |> head()
rp_stats <- summary(rp)
print(rp_stats)
```

Next, we map those predictions into various portfolios (quantiles) and analyse their performance. We specify various weight restrictions, such as the minimum and maximum weight, the minimum and maximum cutoff quantile, and the b parameter that adjusts the amount of investment per leg (b=1 means, we go 100% long and short). We also specify the predictions that should be used for the portfolio formation (e.g., ols_1, xgb_1, xgb_2). 

```{r specify_pf_config}
pf_config <- list(predictions = c("ols_1","xgb_1","xgb_2"),
                  quantile_weight = list(pred_func="quantile_weights",
                    config1=list(quantiles = list(long = 0.20, short = 0.20),allow_short_sale = FALSE,
                      min_weight = -1,  max_weight = 1, b = 1),
                    config2=list(quantiles = list(long = 0.10, short = 0.10),allow_short_sale = FALSE,
                      min_weight = -1,  max_weight = 1, b = 1)))
```

Finally we run the portfolio formation process.

```{r backtesting_portfolios}
pf <- backtesting_portfolios(return_prediction_object = rp, pf_config = pf_config)
```
Let us check the content of pf, and calculate some summary statistics

```{r check_pf}
pf$weights |> head()
pf$portfolio_returns |> head()
pf_stats <- summary(pf)
print(pf_stats)
```

Alternatively, we can also calculate statistics from the `PerformanceAnalytics` package.


```{r check_pf_perf}
library(tidyquant)
# tidyquant::tq_performance_fun_options()
summary(pf)
summary(pf, type = "table.AnnualizedReturns")
summary(pf, type = "table.Distributions")
summary(pf, type = "table.DownsideRisk")
summary(pf, type = "table.DrawdownsRatio")
summary(pf, type = "cov")
```


Now we plot the corresponding cumulative returns of the portfolios

```{r plot_pf}
plot(pf)
```

Alternatively, the plotting function is designed in  a way, that it takes plotting function from the `tidyquant` package as inputs. 

```{r plot_pf_tq, warning=FALSE}
library(tidyquant)
ls("package:PerformanceAnalytics")[grepl("chart",ls("package:PerformanceAnalytics"))]
plot(pf, type = "chart.CumReturns")
plot(pf, type = "charts.PerformanceSummary")
plot(pf, type = "chart.Boxplot")
```

# Implement own Functions

Lets start with a simple random forest implementation. We need to specify the function that should be used for the prediction, the configuration of the function, and the name of the function. The logic is easy: create a function "rf_pred" having arguments: 'train_data', 'test_data', as well as a 'config' that is taken by the prediction function.

```{r specify_rf_config}
rf_config <- list(rf_pred = list(pred_func="rf_pred", 
                                 config1=list(num.trees=100, max.depth=3, mtry=3)))
```

Next we implement the prediction function. The function takes the training data, the test data, and the configuration as arguments. The function returns the predicted returns. The function uses the `randomForest` package to fit a random forest model to the training data and to predict the returns for the test data.

```{r implement_rf}
rf_pred <- function(train_data, test_data, config) {
  train_features <- (train_data[,4:ncol(train_data)])
  train_label <- as.matrix(train_data[,3])
  # add data
  config$x <- train_features
  config$y <- train_label
  # do the training
  fit <- do.call(ranger::ranger, config)
  # do the predictions
  predictions <- as.vector(predict(fit, test_data)$predictions)
  # match preds back to stock_id and date
  predictions <- tibble::tibble(stock_id=test_data$stock_id, date=test_data$date, pred_return=predictions)
  return(predictions)
}
```

Finally, we call the backtesting function with the new configuration. The function returns a data frame with the backtesting results. The data frame contains the following columns: date, return_label, features, rolling, window_size, step_size, offset, in_sample, ml_config, model, predicted returns, actual realized returns, and errors for all predictions. The model column contains the name of the model that was used for the prediction. The prediction column contains the predicted returns. The actual column contains the actual returns. The error column contains the difference between the predicted and the actual returns. By providing the 'rp' object from before, we add an additional prediction.

```{r backtesting_returns_rf}
rp_rf <- backtesting_returns(data=data_ml, return_prediction_object=rp,
   return_label, features, rolling=FALSE, window_size, step_size, offset, in_sample, rf_config, append=FALSE, num_cores=NULL)
```
Next we chack the prediction summary.

```{r analyse_predictions_rf}
rp_rf$predictions |> head()
rp_rf_stats <- summary(rp_rf)
print(rp_rf_stats)
```

Lets create portfolios again.

```{r backtesting_portfolios_rf}
pf_config <- list(predictions = c("xgb_2","rf_1"),
                  quantile_weight = list(pred_func="quantile_weights",
                    config1=list(quantiles = list(long = 0.20, short = 0.20),allow_short_sale = FALSE,
                      min_weight = -1,  max_weight = 1, b = 1),
                    config2=list(quantiles = list(long = 0.10, short = 0.10),allow_short_sale = FALSE,
                      min_weight = -1,  max_weight = 1, b = 1)))
pf_rf <- backtesting_portfolios(return_prediction_object = rp_rf, pf_config = pf_config)
```

And finally summarise the portfolio statistics.

```{r check_pf_rf}
plot(pf_rf)
pf_rf_stats <- summary(pf_rf)
print(pf_rf_stats)
```
